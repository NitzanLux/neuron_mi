{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recurstion old ,  3000\n",
      "recurstion old ,  1000000\n",
      "start job\n",
      "start job\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from create_entropy_estimation import EntropyEstimation\n",
    "from utils.evaluations_utils import *\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sn\n",
    "import re\n",
    "from typing import List\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> add parameters<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models={}\n",
    "regex_match = re.compile('Rat.+CTW')\n",
    "gmax_regex = re.compile('.*_([0-9](?:-[0-9])?(?:_noNMDA)?)_.*')\n",
    "gmax_value_regex = re.compile('([0-9](?:\\.[0-9])?)[a-z,A-Z]*')\n",
    "\n",
    "for i in os.listdir('entropy_data'):\n",
    "    if regex_match.match(i) and os.path.isdir(os.path.join('entropy_data',i)):\n",
    "        models[i] = gmax_regex.match(i).group(1).replace('-','.')\n",
    "        models[i] = models[i].replace('_noNMDA',' AMPA')\n",
    "\n",
    "name_order = list(models.values())\n",
    "# name_order = sorted(name_order,key=lambda x:('AMPA' not in x ,float(gmax_value_regex.match(x).group(0))))\n",
    "name_order = sorted(name_order,key=lambda x:(float(gmax_value_regex.match(x).group(0)),'AMPA' not in x))\n",
    "\n",
    "grouping = {'_noNMDA'}\n",
    "remove_v = True\n",
    "eval_name= 'L5bPC_test_CTW'\n",
    "\n",
    "\n",
    "# models\n",
    "# name_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "{'Rat_L5b_PC_2_Hay_0-4_CTW': '0.4',\n 'Rat_L5b_PC_2_Hay_0-4_noNMDA_CTW': '0.4 AMPA',\n 'Rat_L5b_PC_2_Hay_0-6_CTW': '0.6',\n 'Rat_L5b_PC_2_Hay_0-6_noNMDA_CTW': '0.6 AMPA',\n 'Rat_L5b_PC_2_Hay_0-8_CTW': '0.8',\n 'Rat_L5b_PC_2_Hay_0-8_noNMDA_CTW': '0.8 AMPA',\n 'Rat_L5b_PC_2_Hay_1-2_CTW': '1.2',\n 'Rat_L5b_PC_2_Hay_1-2_noNMDA_CTW': '1.2 AMPA',\n 'Rat_L5b_PC_2_Hay_1-4_CTW': '1.4',\n 'Rat_L5b_PC_2_Hay_1-4_noNMDA_CTW': '1.4 AMPA',\n 'Rat_L5b_PC_2_Hay_1-6_CTW': '1.6',\n 'Rat_L5b_PC_2_Hay_1-6_noNMDA_CTW': '1.6 AMPA',\n 'Rat_L5b_PC_2_Hay_1-8_CTW': '1.8',\n 'Rat_L5b_PC_2_Hay_1-8_noNMDA_CTW': '1.8 AMPA',\n 'Rat_L5b_PC_2_Hay_1_CTW': '1',\n 'Rat_L5b_PC_2_Hay_1_noNMDA_CTW': '1 AMPA',\n 'Rat_L5b_PC_2_Hay_2-5_noNMDA_CTW': '2.5 AMPA',\n 'Rat_L5b_PC_2_Hay_2_CTW': '2',\n 'Rat_L5b_PC_2_Hay_2_noNMDA_CTW': '2 AMPA',\n 'Rat_L5b_PC_2_Hay_3-5_noNMDA_CTW': '3.5 AMPA',\n 'Rat_L5b_PC_2_Hay_3_noNMDA_CTW': '3 AMPA',\n 'Rat_L5b_PC_2_Hay_4-5_noNMDA_CTW': '4.5 AMPA',\n 'Rat_L5b_PC_2_Hay_4_noNMDA_CTW': '4 AMPA',\n 'Rat_L5b_PC_2_Hay_5_noNMDA_CTW': '5 AMPA',\n 'Rat_L5b_PC_2_Hay_current_injection_synapses_0-4_CTW': '0.4',\n 'Rat_L5b_PC_2_Hay_current_injection_synapses_0-6_CTW': '0.6',\n 'Rat_L5b_PC_2_Hay_current_injection_synapses_0-8_CTW': '0.8',\n 'Rat_L5b_PC_2_Hay_current_injection_synapses_1_CTW': '1',\n 'Rat_L5b_PC_2_Hay_current_injection_synapses_2_noNMDA_CTW': '2 AMPA',\n 'Rat_L5b_PC_2_Hay_current_injection_synapses_3_noNMDA_CTW': '3 AMPA',\n 'Rat_L5b_PC_2_Hay_current_injection_synapses_4_noNMDA_CTW': '4 AMPA',\n 'Rat_L5b_PC_2_Hay_current_injection_synapses_5_noNMDA_CTW': '5 AMPA',\n 'Rat_L5b_PC_2_Hay_current_injection_synapses_6_noNMDA_CTW': '6 AMPA',\n 'Rat_L5b_PC_2_Hay_current_injection_synapses_noNMDA_0-4_CTW': '0.4',\n 'Rat_L5b_PC_2_Hay_current_injection_synapses_noNMDA_0-6_CTW': '0.6',\n 'Rat_L5b_PC_2_Hay_current_injection_synapses_noNMDA_0-8_CTW': '0.8',\n 'Rat_L5b_PC_2_Hay_current_injection_synapses_noNMDA_1_CTW': '1',\n 'Rat_L5b_PC_2_Hay_DC_30_CTW': '2',\n 'Rat_L5b_PC_2_Hay_DC_40_CTW': '2',\n 'Rat_L5b_PC_2_Hay_DC_50_CTW': '2',\n 'Rat_L5b_PC_2_Hay_DC_60_CTW': '2',\n 'Rat_L5b_PC_2_Hay_DC_80_CTW': '2',\n 'Rat_L5b_PC_2_Hay_factor_0-2_DC_-10_CTW': '0.2',\n 'Rat_L5b_PC_2_Hay_factor_0-2_DC_-110_CTW': '0.2',\n 'Rat_L5b_PC_2_Hay_factor_0-2_DC_-20_CTW': '0.2',\n 'Rat_L5b_PC_2_Hay_factor_0-2_DC_-30_CTW': '0.2',\n 'Rat_L5b_PC_2_Hay_factor_0-2_DC_-40_CTW': '0.2',\n 'Rat_L5b_PC_2_Hay_factor_0-2_DC_-50_CTW': '0.2',\n 'Rat_L5b_PC_2_Hay_factor_0-2_DC_-60_CTW': '0.2',\n 'Rat_L5b_PC_2_Hay_factor_0-2_DC_-70_CTW': '0.2',\n 'Rat_L5b_PC_2_Hay_factor_0-2_DC_-80_CTW': '0.2',\n 'Rat_L5b_PC_2_Hay_factor_0-2_DC_-90_CTW': '0.2',\n 'Rat_L5b_PC_2_Hay_factor_0-2_DC_0_CTW': '0',\n 'Rat_L5b_PC_2_Hay_factor_0-2_DC_10_CTW': '0.2',\n 'Rat_L5b_PC_2_Hay_factor_0-2_DC_20_CTW': '0.2',\n 'Rat_L5b_PC_2_Hay_factor_0-2_DC_30_CTW': '0.2',\n 'Rat_L5b_PC_2_Hay_noNMDA_2-5_CTW': '2.5',\n 'Rat_L5b_PC_2_Hay_noNMDA_3-5_CTW': '3.5',\n 'Rat_L5b_PC_2_Hay_noNMDA_3_CTW': '3',\n 'Rat_L5b_PC_2_Hay_noNMDA_4-5_CTW': '4.5',\n 'Rat_L5b_PC_2_Hay_noNMDA_4_CTW': '4',\n 'Rat_L5b_PC_2_Hay_noNMDA_5_CTW': '5',\n 'Rat_L5b_PC_2_Hay_noNMDA_factor_1_DC_-10_CTW': '1',\n 'Rat_L5b_PC_2_Hay_noNMDA_factor_1_DC_-110_CTW': '1',\n 'Rat_L5b_PC_2_Hay_noNMDA_factor_1_DC_-20_CTW': '1',\n 'Rat_L5b_PC_2_Hay_noNMDA_factor_1_DC_-30_CTW': '1',\n 'Rat_L5b_PC_2_Hay_noNMDA_factor_1_DC_-40_CTW': '1',\n 'Rat_L5b_PC_2_Hay_noNMDA_factor_1_DC_-50_CTW': '1',\n 'Rat_L5b_PC_2_Hay_noNMDA_factor_1_DC_-60_CTW': '1',\n 'Rat_L5b_PC_2_Hay_noNMDA_factor_1_DC_-70_CTW': '1',\n 'Rat_L5b_PC_2_Hay_noNMDA_factor_1_DC_-80_CTW': '1',\n 'Rat_L5b_PC_2_Hay_noNMDA_factor_1_DC_-90_CTW': '1',\n 'Rat_L5b_PC_2_Hay_noNMDA_factor_1_DC_0_CTW': '0',\n 'Rat_L5b_PC_2_Hay_noNMDA_factor_1_DC_10_CTW': '1',\n 'Rat_L5b_PC_2_Hay_noNMDA_factor_1_DC_20_CTW': '1',\n 'Rat_L5b_PC_2_Hay_noNMDA_factor_1_DC_30_CTW': '1'}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m df, m_names \u001B[38;5;241m=\u001B[39m \u001B[43md\u001B[49m\u001B[38;5;241m.\u001B[39mget_as_dataframe()\n\u001B[0;32m      2\u001B[0m models \u001B[38;5;241m=\u001B[39m {k:v \u001B[38;5;28;01mfor\u001B[39;00m k,v \u001B[38;5;129;01min\u001B[39;00m models\u001B[38;5;241m.\u001B[39mitems()}\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# for i in models.keys():\u001B[39;00m\n\u001B[0;32m      4\u001B[0m     \u001B[38;5;66;03m# df[df['model']==i]['model'] = models[i]\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# models = {v:v for v in models.values()}\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "df, m_names = d.get_as_dataframe()\n",
    "models = {k:v for k,v in models.items()}\n",
    "# for i in models.keys():\n",
    "    # df[df['model']==i]['model'] = models[i]\n",
    "# models = {v:v for v in models.values()}\n",
    "df.replace(inplace=True,to_replace=models)\n",
    "\n",
    "if remove_v:\n",
    "    v_columns_to_remove=[]\n",
    "    for i in df.columns:\n",
    "        if '_v_'in i:\n",
    "            v_columns_to_remove.append(i)\n",
    "    df = df.drop(columns=v_columns_to_remove)\n",
    "df['type']=df['model'].str.contains('AMPA')\n",
    "# df.replace(inplace=True,to_replace={i:i.replace(' AMPA','')for i in models.values()})\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Nones and inf columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print([len(d.data[i]) for i in d.data.keys()])\n",
    "print(len(d.keys))\n",
    "print(df.file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inf_nan_columns = []\n",
    "for i in df.columns:\n",
    "    dfinf = df[i]\n",
    "    if 'ENTROPY' not in i:\n",
    "        continue\n",
    "    if dfinf.dtype == object:\n",
    "        dfinf = np.array(list(dfinf))\n",
    "\n",
    "    if np.any(np.isinf(dfinf)):\n",
    "        inf_nan_columns.append(i)\n",
    "print(inf_nan_columns)\n",
    "df.drop(inf_nan_columns, axis=1, inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Distributions visualization over the CI <h2>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "box_plot_data = {}\n",
    "colors_index={}\n",
    "c_obj=set()\n",
    "temp_df= d\n",
    "for i, m in enumerate(name_order):\n",
    "    colors_index[m]=f'C{i}'\n",
    "    for c in df.columns:\n",
    "        if 'CI'in c:\n",
    "            c_obj.add(c)\n",
    "\n",
    "for c in c_obj:\n",
    "    fig, ax = plt.subplots()\n",
    "    bpa=[]\n",
    "    keylen = len(box_plot_data)\n",
    "    c_arr=[]\n",
    "    i=0\n",
    "    r = sn.violinplot(data=df,y=c,x='model',hue='type',width=1,orient='v', order=name_order)\n",
    "\n",
    "    r.set_xticklabels(r.get_xticklabels(),rotation=30)\n",
    "    ax.set_ylabel('Complexity index')\n",
    "\n",
    "    ax.set_title(f'{c.replace(\"CI\",\"\").replace(\"_\",\" \")}Complexity Index ')\n",
    "    plt.subplots_adjust(bottom=0.4)\n",
    "\n",
    "    fig\n",
    "    save_large_plot(fig, f\"boxplot{c}_{len(d)}.png\", tags=eval_name)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% box plot complexity\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "hist plot of the cis\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in tqdm(df.columns):\n",
    "    if not ('ENTROPY' in c and 'CI' in c):\n",
    "        continue\n",
    "    df = df.sort_values(['key'])\n",
    "    datas = []\n",
    "    ci_data = []\n",
    "    for i in name_order:\n",
    "        ci_data.append(np.vstack(df[df['model'] == i][c].tolist()))\n",
    "    dist = []\n",
    "    bins = 20\n",
    "    # all_data= np.vstack(datas)\n",
    "    fig, ax = plt.subplots()\n",
    "    for j, n in enumerate(name_order):\n",
    "        if np.any(np.isnan(ci_data[j])):\n",
    "            print(n)\n",
    "        frequency, bins = np.histogram(ci_data[j][~np.isnan(ci_data[j])], bins=bins)\n",
    "        # print(frequency)\n",
    "        # frequency = frequency / np.sum(frequency)\n",
    "        ax.stairs(frequency, bins, fill=True, label=n, alpha=0.4)\n",
    "    fig.legend(loc=1, borderaxespad=3)\n",
    "    ax.set_title(c.lower().replace('_', ' ').capitalize())\n",
    "    ax.set_ylabel('P(ci)')\n",
    "    ax.set_xlabel('ci value')\n",
    "    save_large_plot(fig,f'dist_1d_{c}_{len(d)}.png',tags=eval_name)\n",
    "    fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "name_order_dict= {n:i for i,n in enumerate(name_order)}\n",
    "df = df.sort_values(['model'],key = lambda x: [name_order_dict[i] for i in x])\n",
    "\n",
    "for c in (df.columns):\n",
    "    if not ('ENTROPY' in c and 'CI' in c):\n",
    "        continue\n",
    "    fig, ax = plt.subplots()\n",
    "    res = sn.kdeplot(data=df,x = f'{c}', shade=False,hue='model',alpha=0.6)#thresh\n",
    "    # for i in models.keys():\n",
    "        # print(np.std(df[df['model'==i]][c]),c,i)\n",
    "    ax.set_title(c.lower().replace('_', ' ').capitalize())\n",
    "    ax.set_ylabel('P(ci)')\n",
    "    ax.set_xlabel('ci value')\n",
    "    # ax.set_yscale('log')\n",
    "\n",
    "    save_large_plot(fig,f'dist_1d_{c}_{len(d)}.png',tags=eval_name)\n",
    "    fig"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4> norm sorted <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['key'])\n",
    "box_plot_data = {}\n",
    "colors_index={}\n",
    "c_obj=set()\n",
    "for i, m in enumerate(name_order):\n",
    "    colors_index[m]=f'C{i}'\n",
    "    for c in df.columns:\n",
    "        if 'CI'in c:\n",
    "            c_obj.add(c)\n",
    "for c in c_obj:\n",
    "    diff_vec = []\n",
    "    for j in name_order:\n",
    "        # a = df[(df['model'] == j)][c].values\n",
    "        diff_vec.append(df[(df['model'] == j)][c].values)\n",
    "    diff_vec = np.array(diff_vec)\n",
    "    temp_diff_vec = diff_vec.copy()\n",
    "    a = np.argsort(np.linalg.norm(diff_vec, axis=0))\n",
    "    fig, ax = plt.subplots()\n",
    "    mat = diff_vec[:, a]\n",
    "    im = ax.matshow(mat)\n",
    "    ax.set_aspect(mat.shape[1]//(mat.shape[0]*2))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xlabel(f'Sorted Trial index (n = {diff_vec.shape[1]:,})')\n",
    "    ax.set_yticks(range(len(name_order)), name_order)\n",
    "    ax.set_title(f'Norm Sorted SE Complexity Index {c.lower().replace(\"_\",\" \").capitalize()}')\n",
    "    fig.colorbar(im, location=\"bottom\")\n",
    "    plt.tight_layout()\n",
    "    save_large_plot(fig, f'norm_wise_orderd_matrix{c}_{len(d)}.png', eval_name)\n",
    "\n",
    "    fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> spike count per simulation <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#spike_count\n",
    "fig, ax = plt.subplots()\n",
    "datas = []\n",
    "for i in name_order:\n",
    "    datas.append(np.array(df[df['model'] == i]['spikes'].tolist()))\n",
    "    d_size=datas[-1].shape[1]\n",
    "    datas[-1]=datas[-1].sum(axis=1)\n",
    "    datas[-1]=datas[-1]*1000/d_size\n",
    "    # a=np.mean(np.array(datas[-1]),axis=1)\n",
    "    # print(i, np.mean(np.array(datas[-1]),axis=1))\n",
    "names_for_plots_labels = [(mn + f\" ($\\mu$ = {np.round(np.mean(np.array(datas[i])), 2)})\") for i, mn in\n",
    "                          enumerate(name_order)]\n",
    "d_arr=np.vstack(datas)\n",
    "bins = np.linspace(np.min(d_arr),np.max(d_arr),10)\n",
    "\n",
    "\n",
    "ax.hist(datas, bins=bins,rwidth=1, label=names_for_plots_labels, alpha=1, align='mid')\n",
    "ax.set_title('Spike Count Per Trial')\n",
    "# ax.set_yscale('log')\n",
    "ax.set_xlabel('Firing rate(Hz)')\n",
    "ax.set_ylabel('Number of Occurrences')\n",
    "# ax.set_xticks(bins[::5] - 0.5, bins[::5])\n",
    "fig.legend(bbox_to_anchor=[0.9, 0.875])\n",
    "# save_large_plot(fig, 'spike_count.png', name_order)\n",
    "save_large_plot(fig,f'spike_count_{len(d)}.png',tags=eval_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in tqdm(df.columns):\n",
    "    if not ('ENTROPY' in i and 'CI' in i):\n",
    "        continue\n",
    "    datas=[]\n",
    "    df = df.sort_values(by=['key'])\n",
    "    prev_index=None\n",
    "    indexes=None\n",
    "    for m in name_order:\n",
    "        prev_index=indexes\n",
    "        indexes=df[df['model'] == m]['key'].tolist()\n",
    "        datas.append(np.hstack(df[df['model'] == m][i].tolist()))\n",
    "        if prev_index is not None:\n",
    "            assert all(i==j for i,j in zip(prev_index,indexes)),'\\n'.join([('' if i==j else str((i,j)))for i,j in zip(prev_index,indexes)])\n",
    "    for j in combination_sorting(name_order):\n",
    "        first_index, second_index = j[0],j[1]\n",
    "        fig, ax = plt.subplots()\n",
    "        nans = np.logical_or(np.isnan(datas[first_index]),np.isnan(datas[second_index]))\n",
    "        lims = (np.min(np.vstack((datas[first_index][~nans], datas[second_index][~nans]))),\n",
    "                np.max(np.vstack((datas[first_index][~nans], datas[second_index][~nans]))))\n",
    "        H, xedges, yedges = np.histogram2d(datas[first_index][~nans], datas[second_index][~nans], range=np.array([lims, lims]),\n",
    "                                           bins=50)\n",
    "        # replace zeroes with nan\n",
    "        H[H == 0] = np.nan\n",
    "        im = ax.imshow(H.T, interpolation='nearest', origin='lower', extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "                       )\n",
    "        # , norm=colors.LogNorm())\n",
    "        ax.plot(lims, lims, color='black')\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(np.array(datas[first_index]), datas[second_index])\n",
    "        reg_intercep = intercept\n",
    "        reg_coef = slope\n",
    "        x = lims\n",
    "        y = [reg_intercep + lims[0] * reg_coef, reg_intercep + lims[1] * reg_coef]\n",
    "        ax.plot(x, y, color='red')\n",
    "        fig.colorbar(im)\n",
    "        ax.set_xlabel(name_order[first_index])\n",
    "        ax.set_ylabel(name_order[second_index])\n",
    "        ax.set_ylim(lims)\n",
    "        ax.set_xlim(lims)\n",
    "        ax.set_title(\n",
    "            f\"{name_order[first_index]} and {name_order[second_index]} trials {i} \\nn = {len(datas[second_index]) * 2:,} ,$R^2$ = {np.round(r_value ** 2, 4)}\")\n",
    "        fig\n",
    "        save_large_plot(fig, f\"pairwise_2dhist_{i}_{name_order[first_index]}_{name_order[second_index]}_{len(d)}.png\", tags=eval_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% print temporal mean and error\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# %% print temporal mean and error\n",
    "relevant_cols_msx=[]\n",
    "relevant_cols_ci=[]\n",
    "representative_msx=set()\n",
    "\n",
    "for i in df.columns:\n",
    "    if 'MSx'in i:\n",
    "        relevant_cols_msx.append(i)\n",
    "        representative_msx.add(i[:-len('_v_CI')])\n",
    "\n",
    "    elif 'CI' in i:\n",
    "        relevant_cols_ci.append(i)\n",
    "representative_msx = {k:i for i,k in enumerate(representative_msx)}\n",
    "df = df.sort_values(['key'])\n",
    "datas = {}\n",
    "ci_data={}\n",
    "threshold=None\n",
    "\n",
    "for m in name_order:\n",
    "    datas[m]=[]\n",
    "    ci_data[m]=[]\n",
    "    for c in relevant_cols_msx:\n",
    "        datas[m].append(np.vstack(df[df['model'] == m][c].tolist()))\n",
    "    for c in relevant_cols_ci:\n",
    "        ci_data[m].append(np.vstack(df[df['model'] == m][c].tolist()))\n",
    "\n",
    "# ci_data = np.hstack(ci_data)\n",
    "# indexes=np.arange(ci_data[0].shape[0])\n",
    "sorted(relevant_cols_msx,key = lambda x: representative_msx[x[:-len('_v_CI')]]+int('_v_' in x))\n",
    "for i,c in enumerate(relevant_cols_msx):\n",
    "    if i%2==0 :\n",
    "        fig, ax = plt.subplots(1,1+int(not remove_v))\n",
    "    axx = ax if remove_v else ax[i%2]\n",
    "    for m in name_order:\n",
    "        if threshold is not None:\n",
    "            mean = np.mean(datas[m][i], axis=0)\n",
    "            std =  np.std(datas[m][i], axis=0)\n",
    "        else:\n",
    "            mean = np.mean(datas[m][i], axis=0)\n",
    "            std = np.std(datas[m][i], axis=0)\n",
    "        axx.plot(np.arange(datas[m][i].shape[1]), mean, label=f'{m}')\n",
    "        axx.fill_between(np.arange(datas[m][i].shape[1]), mean - std, mean + std, alpha=0.1)\n",
    "\n",
    "    axx.legend()\n",
    "    # if threshold is not None:\n",
    "    # ax.set_title(\n",
    "    # f'Average SE Across Different Time Scales (n = {len(datas[0]) * len(datas):,}) \\nCi value {\"greater\" if direction > 0 else \"lower\"} than {threshold_value:0.4}')\n",
    "    # else:\n",
    "    #     ax.set_title(f'Average SE Across Different Time Scales (n = {len(datas[0]) * len(datas):,})')\n",
    "    axx.set_xlabel('Time Scales')\n",
    "    axx.set_ylabel('SE value')\n",
    "    axx.set_title(c.lower().replace('_',' ').capitalize())\n",
    "    if i%2==1:\n",
    "        save_large_plot(fig,f'temporal_msx_{c[:-len(\"_v_CI\")]}_{len(d)}.png',tags=eval_name)\n",
    "\n",
    "    fig"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> show traces <h2>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h3> by input max and min <h3>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# models=name_order\n",
    "models_to_remove = ['reduction']#,'AMPA gmax 0.0004']\n",
    "# ci = 'APPROXIMATE_ENTROPY_s_CI'\n",
    "# ci = 'FUZZY_ENTROPY_s_CI'\n",
    "ci=EntropyTypes.DISCRETE_SAMPLE_ENTROPY.name+\"_s_CI\"\n",
    "df = df.sort_values(['key'])\n",
    "diff_vec = []\n",
    "keys_vec = []\n",
    "cur_model_order=[]\n",
    "for j in tqdm(name_order):\n",
    "    if j in models_to_remove:\n",
    "        continue\n",
    "    cur_model_order.append(j)\n",
    "    keys_vec.append(df[(df['model'] == j)]['voltage'].values)\n",
    "    diff_vec.append(df[(df['model'] == j)][ci].values)\n",
    "diff_vec = np.array(diff_vec)\n",
    "temp_diff_vec = diff_vec.copy()\n",
    "a = diff_vec.sum(axis=0)\n",
    "amax = np.argmax(a)\n",
    "amin = np.argmin(a)\n",
    "# amid =np.argwhere(a==np.percentile(a,50,method='nearest'))[0][0]\n",
    "amean =(np.abs(a - a.mean())).argmin()\n",
    "for i,n in enumerate(cur_model_order):\n",
    "    fig,ax = plt.subplots(3)\n",
    "    ax[0].plot(keys_vec[i][amax])\n",
    "    ax[2].plot(keys_vec[i][amin])\n",
    "    ax[1].plot(keys_vec[i][amean])\n",
    "\n",
    "    ax[0].set_title(f'Max CI {np.round(diff_vec[i][amax],5)}')\n",
    "    ax[1].set_title(f'Mean CI {np.round(diff_vec[i][amean],5)}')\n",
    "    ax[2].set_title(f'Min ci {np.round(diff_vec[i][amin],5)}')\n",
    "    ax[0].set_xticks([])\n",
    "    ax[1].set_xticks([])\n",
    "    for i in range(3):\n",
    "        ax[i].set_xlim([2000,3500])\n",
    "    ax[2].set_xlabel('Time(ms)')\n",
    "    [ax[i].set_ylabel('Voltage (mv)') for i in range(3)]\n",
    "    fig.suptitle(f\"{n} by {ci.lower().replace('_',' ').replace('CI','').capitalize()}\")\n",
    "    save_large_plot(fig,f'mkl_traces_{n}_{ci}.png',tags=eval_name)\n",
    "    fig.tight_layout()\n",
    "    fig"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "models_to_remove = ['reduction']#,'AMPA gmax 0.0004']\n",
    "ci = EntropyTypes.DISCRETE_SAMPLE_ENTROPY.name+'_s_CI'\n",
    "# ci = 'FUZZY_ENTROPY_s_CI'\n",
    "\n",
    "df = df.sort_values(['key'])\n",
    "diff_vec = []\n",
    "keys_vec = []\n",
    "cur_model_order=[]\n",
    "for j in name_order:\n",
    "    if j in models_to_remove:\n",
    "        continue\n",
    "    cur_model_order.append(j)\n",
    "    keys_vec.append(df[(df['model'] == j)]['voltage'].values)\n",
    "    diff_vec.append(df[(df['model'] == j)][ci].values)\n",
    "diff_vec = np.array(diff_vec)\n",
    "temp_diff_vec = diff_vec.copy()\n",
    "amax = np.argmax(diff_vec,axis=1)\n",
    "amin = np.argmin(diff_vec,axis=1)\n",
    "# amid =np.argwhere(a==np.percentile(a,50,method='nearest'))[0][0]\n",
    "amean =(np.abs(diff_vec - diff_vec.mean(axis=1)[:,np.newaxis])).argmin(axis=1)\n",
    "for i,n in enumerate(cur_model_order):\n",
    "    fig,ax = plt.subplots(3)\n",
    "    ax[0].plot(keys_vec[i][amax[i]])\n",
    "    ax[2].plot(keys_vec[i][amin[i]])\n",
    "    ax[1].plot(keys_vec[i][amean[i]])\n",
    "\n",
    "    ax[0].set_title(f'Max CI {np.round(diff_vec[i][amax[i]],5)}')\n",
    "    ax[1].set_title(f'Mean CI {np.round(diff_vec[i][amean[i]],5)}')\n",
    "    ax[2].set_title(f'Min ci {np.round(diff_vec[i][amin[i]],5)}')\n",
    "    ax[0].set_xticks([])\n",
    "    ax[1].set_xticks([])\n",
    "    ax[2].set_xlabel('Time(ms)')\n",
    "    [ax[i].set_ylabel('Voltage (mv)') for i in range(3)]\n",
    "    fig.suptitle(f\"{n} by {ci.lower().replace('_',' ').replace('CI','').capitalize()}\")\n",
    "    save_large_plot(fig,f'traces_{n}_{ci}_different_files.png',tags=eval_name)\n",
    "    fig.tight_layout()\n",
    "    fig"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> correlation <h2>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#ampa\n",
    "\n",
    "corrdf = df.copy()\n",
    "# corrdf.columns\n",
    "to_keep={'model','DISCRETE_SAMPLE_ENTROPY_s_CI','spikes'}\n",
    "corrdf.drop(columns = (set(df.columns)-to_keep),inplace=True)\n",
    "corrdf.spikes =np.nansum(corrdf.spikes.to_list(),axis=1)\n",
    "# corrdf.model = [float(gmax_value_regex.match(i).group(0)) for i in corrdf.model]\n",
    "corrdf.corr().style.background_gradient(cmap=\"Blues\")\n",
    "del corrdf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "s_arr=[]\n",
    "c_arr=[]\n",
    "# df.columns\n",
    "temp_df = df.sort_values(['key','model'])\n",
    "cur_key=None\n",
    "for idx,i in temp_df.iterrows():\n",
    "    if cur_key is None or cur_key!=i.key:\n",
    "        cur_key=i.key\n",
    "        s_arr.append([])\n",
    "        c_arr.append([])\n",
    "    s_arr[-1].append(np.sum(i.spikes.tolist())*1000/len(i.spikes.tolist()))\n",
    "    c_arr[-1].append(i.DISCRETE_SAMPLE_ENTROPY_s_CI)\n",
    "    # d_arr[i.key]={}\n",
    "s_arr = np.array(s_arr)\n",
    "c_arr = np.array(c_arr)\n",
    "fig,ax = plt.subplots(2)\n",
    "lims=[0,c_arr.shape[1]-1]\n",
    "s_arr_x= np.zeros_like(s_arr)+np.arange(s_arr.shape[1])\n",
    "slope, intercept, r_value, p_value, std_err = linregress(s_arr_x.flatten(), s_arr.flatten())\n",
    "reg_intercep = intercept\n",
    "reg_coef = slope\n",
    "x = lims\n",
    "y = [reg_intercep + lims[0] * reg_coef, reg_intercep + lims[1] * reg_coef]\n",
    "ax[0].plot(s_arr.T,alpha=0.3)\n",
    "ax[0].plot(x, y, color='red',linewidth=2)\n",
    "ax[0].set_title('Fr $R^{2}$ = '+f'{r_value**2}')\n",
    "\n",
    "print('s',np.std(s_arr,axis=0))\n",
    "c_arr_x= np.zeros_like(s_arr)+np.arange(c_arr.shape[1])\n",
    "slope, intercept, r_value, p_value, std_err = linregress(c_arr_x.flatten(), c_arr.flatten())\n",
    "reg_intercep = intercept\n",
    "reg_coef = slope\n",
    "x = lims\n",
    "y = [reg_intercep + lims[0] * reg_coef, reg_intercep + lims[1] * reg_coef]\n",
    "ax[1].plot(c_arr.T,alpha=0.3)\n",
    "ax[1].plot(x, y, color='red',linewidth=2)\n",
    "ax[1].set_title('CI $R^{2}$ = '+f'{r_value**2}')\n",
    "\n",
    "\n",
    "print('c',np.std(c_arr,axis=0))\n",
    "ax[1].set_xticks(np.arange(c_arr.shape[1]),name_order)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
