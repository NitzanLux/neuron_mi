{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start job\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.evaluations_utils import *\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> add parameters<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{tag:plot name}\n",
    "models = {'davids_ergodic_train_fnum_580_snum74240':'NMDA','reduction_ergodic_train_fnum_580_snum74187':'reduction','train_AMPA_gmax2_fnum_580_snum74240':'AMPA'}\n",
    "name_order = ['NMDA','reduction','AMPA']\n",
    "d_ratio=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mMemoryError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m d \u001B[38;5;241m=\u001B[39m \u001B[43mModelsSEData\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeys\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# d.sample_from_set(d_ratio)\u001B[39;00m\n\u001B[0;32m      3\u001B[0m d\u001B[38;5;241m.\u001B[39mload_data(\u001B[38;5;241m0.1\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\university\\Idan_Lab\\neuron_mi\\utils\\evaluations_utils.py:61\u001B[0m, in \u001B[0;36mModelsSEData.__init__\u001B[1;34m(self, tags)\u001B[0m\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_tags):\n\u001B[0;32m     60\u001B[0m     files\u001B[38;5;241m=\u001B[39m[]\n\u001B[1;32m---> 61\u001B[0m     entropy_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[43mEntropyObject\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_list\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mentropy_data\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m.pkl\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mvalues())\n\u001B[0;32m     62\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m j \u001B[38;5;129;01min\u001B[39;00m entropy_list:\n\u001B[0;32m     63\u001B[0m         files\u001B[38;5;241m.\u001B[39mappend(j\u001B[38;5;241m.\u001B[39mfile_name)\n",
      "File \u001B[1;32m~\\Documents\\university\\Idan_Lab\\neuron_mi\\create_entropy_score.py:182\u001B[0m, in \u001B[0;36mEntropyObject.load_list\u001B[1;34m(path)\u001B[0m\n\u001B[0;32m    179\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    180\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_list\u001B[39m(path):\n\u001B[0;32m    181\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(path,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m file:\n\u001B[1;32m--> 182\u001B[0m         \u001B[38;5;28mobject\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mpickle\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    184\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mobject\u001B[39m\n",
      "\u001B[1;31mMemoryError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "d = ModelsSEData(models.keys())\n",
    "# d.sample_from_set(d_ratio)\n",
    "d.load_data(0.1)\n",
    "df, m_names = d.get_as_dataframe()\n",
    "models = {k[:k.find(\"_fnum\")]:v for k,v in models.items()}\n",
    "# for i in models.keys():\n",
    "    # df[df['model']==i]['model'] = models[i]\n",
    "# models = {v:v for v in models.values()}\n",
    "temp = {k:v for v,k in models.items()}\n",
    "name_order = [temp[i] if i not in models else i for i in name_order]\n",
    "df.replace(inplace=True,to_replace=models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Nones and inf columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inf_nan_columns = []\n",
    "for i in df.columns:\n",
    "    dfinf = df[i]\n",
    "    if 'ENTROPY' not in i:\n",
    "        continue\n",
    "    if dfinf.dtype == object:\n",
    "        dfinf = np.array(list(dfinf))\n",
    "\n",
    "    if np.any(np.isinf(dfinf)):\n",
    "        inf_nan_columns.append(i)\n",
    "print(inf_nan_columns)\n",
    "df.drop(inf_nan_columns, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<h2> Distributions visualization over the CI <h2>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "box_plot_data = {}\n",
    "colors_index={}\n",
    "c_obj=set()\n",
    "for i, m in enumerate(name_order):\n",
    "    colors_index[m]=f'C{i}'\n",
    "    for c in df.columns:\n",
    "        if 'CI'in c:\n",
    "            c_obj.add(c[:-len('_s_CI')])\n",
    "for i, m in enumerate(name_order):\n",
    "    colors_index[m]=f'C{i}'\n",
    "    for c in df.columns:\n",
    "        if 'CI'in c:\n",
    "            if c not in box_plot_data:\n",
    "                box_plot_data[c]=[]\n",
    "            box_plot_data[c].append(df[df['model'] == m][c].tolist())\n",
    "            box_plot_data[c][-1] = np.array(box_plot_data[c][-1])\n",
    "for c in c_obj:\n",
    "    fig, ax = plt.subplots()\n",
    "    bpa=[]\n",
    "    keylen = len(box_plot_data)\n",
    "    c_arr=[]\n",
    "    i=0\n",
    "    for k in box_plot_data.keys():\n",
    "        if not c in k:\n",
    "            continue\n",
    "        c_arr.append(k)\n",
    "        for j,m in enumerate(name_order):\n",
    "            print([j+(i*(len(name_order)+1))])\n",
    "            bp = ax.boxplot(box_plot_data[k][j],positions=[j+(i*(len(name_order)+1))],patch_artist=True, showfliers=False)\n",
    "            bp['boxes'][0].set_facecolor(colors_index[m])\n",
    "            bpa.append(bp)\n",
    "        i+=1\n",
    "\n",
    "    ax.set_ylabel('Complexity index')\n",
    "    # ax.set_xticks((np.arange(len(name_order)+1)*len(box_plot_data)))\n",
    "    print(np.arange(0,(len(name_order)+1)*len(c_arr),len(name_order)+1)+len(name_order)/2)\n",
    "    a = ax.set_xticks(np.arange(0,(len(name_order)+1)*len(c_arr),len(name_order)+1)+len(name_order)/2-0.5,c_arr)\n",
    "\n",
    "    print(a)\n",
    "    # vertical alignment of xtick labels\n",
    "    # va = [ 0, -.05, 0, -.05, -.05, -.05 ]\n",
    "    # for t, y in zip( ax.get_xticklabels( ), va ):\n",
    "    #     t.set_y( y )\n",
    "    for k,v in colors_index.items():\n",
    "        ax.plot([],[],color=v,label=models[k])\n",
    "    # ax.set_yscale('log')\n",
    "\n",
    "    # ax.tick_params( axis='x', which='minor', direction='out', length=30 )\n",
    "    # ax.tick_params( axis='x', which='major', bottom='off', top='off' )\n",
    "    # ax.set_xticks(np.arange(len(name_order)) + 1, names_for_plots)\n",
    "    # ax.set_title(f'Sample Entropy Complexity Index (n = {len(box_plot_data[0]) * len(box_plot_data):,})')\n",
    "    plt.subplots_adjust(bottom=0.4)\n",
    "    plt.legend()\n",
    "\n",
    "    fig\n",
    "    save_large_plot(fig, f\"boxplot{c}_{len(d)}.png\", tags=d.data_tags)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% box plot complexity\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "box_plot_data = {}\n",
    "colors_index={}\n",
    "c_obj=set()\n",
    "for i, m in enumerate(name_order):\n",
    "    colors_index[m]=f'C{i}'\n",
    "    for c in df.columns:\n",
    "        if 'CI'in c:\n",
    "            c_obj.add(c[:-len('_s_CI')])\n",
    "            if c not in box_plot_data:\n",
    "                box_plot_data[c]=[]\n",
    "            box_plot_data[c].append(df[df['model'] == name_order[i]][c].tolist())\n",
    "            box_plot_data[c][-1] = np.array(box_plot_data[c][-1])\n",
    "\n",
    "# create data\n",
    "# Evaluate a gaussian kde on a regular grid of nbins x nbins over data extents\n",
    "\n",
    "for i in tqdm(c_obj):\n",
    "    fig, ax = plt.subplots()\n",
    "    nbins = 300\n",
    "    for j,m in enumerate(name_order):\n",
    "        x,y= box_plot_data[i+'_s_CI'][j],box_plot_data[i+'_v_CI'][j]\n",
    "        c = ax.scatter(x,y,alpha=0.3,s=0.01)\n",
    "        ax.plot([],[],color=c.get_facecolor(),label=f'{models[m]}',alpha=1)\n",
    "    ax.set_ylabel('v')\n",
    "    ax.set_xlabel('s')\n",
    "    fig.legend(loc=1)\n",
    "    ax.set_title(f'v and s scatter plot ci{i}')\n",
    "    save_large_plot(fig,f'scttervs_{i}_{len(d)}.png',tags=d.data_tags)\n",
    "    fig\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "scatter plot of the cis\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in tqdm(df.columns):\n",
    "    if not ('ENTROPY' in c and 'CI' in c):\n",
    "        continue\n",
    "    df = df.sort_values(['key'])\n",
    "    datas = []\n",
    "    ci_data = []\n",
    "    for i in name_order:\n",
    "        # datas.append(np.vstack(df[df['model'] == i][c].tolist()))\n",
    "        ci_data.append(np.vstack(df[df['model'] == i][c].tolist()))\n",
    "    dist = []\n",
    "    bins = 200\n",
    "    # all_data= np.vstack(datas)\n",
    "    fig, ax = plt.subplots()\n",
    "    for j, n in enumerate(name_order):\n",
    "        frequency, bins = np.histogram(ci_data[j], bins=bins)\n",
    "        frequency = frequency / np.sum(frequency)\n",
    "        ax.stairs(frequency, bins, fill=True, label=models[n], alpha=0.4)\n",
    "    fig.legend(loc=1, borderaxespad=3)\n",
    "    ax.set_title(c.lower().replace('_', ' ').capitalize())\n",
    "    ax.set_ylabel('P(ci)')\n",
    "    ax.set_xlabel('ci value')\n",
    "    save_large_plot(fig,f'dist_1d_{c}_{len(d)}.png',tags=d.data_tags)\n",
    "    fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_plot_data = {}\n",
    "colors_index={}\n",
    "c_obj=set()\n",
    "for i, m in enumerate(name_order):\n",
    "    colors_index[m]=f'C{i}'\n",
    "    for c in df.columns:\n",
    "        if 'CI'in c:\n",
    "            c_obj.add(c[:-len('_s_CI')])\n",
    "for i, m in enumerate(name_order):\n",
    "    colors_index[m]=f'C{i}'\n",
    "    for c in df.columns:\n",
    "        if 'CI'in c:\n",
    "            if c not in box_plot_data:\n",
    "                box_plot_data[c]=[]\n",
    "            box_plot_data[c].append(df[df['model'] == m][c].tolist())\n",
    "            box_plot_data[c][-1] = np.array(box_plot_data[c][-1])\n",
    "for c in tqdm(c_obj):\n",
    "    # for i,m in enumerate(name_order):\n",
    "    res = sn.kdeplot(data=df,y = f'{c}_v_CI',x =f'{c}_s_CI', shade=False,hue='model',alpha=0.6)#thresh\n",
    "    plt.ylabel('v')\n",
    "    plt.xlabel('s')\n",
    "    plt.title(c.lower().replace('_',' ').capitalize())\n",
    "    save_large_plot(plt,f'kde{c}_{len(d)}.png',tags=d.data_tags)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h4> norm sorted <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['key'])\n",
    "box_plot_data = {}\n",
    "colors_index={}\n",
    "c_obj=set()\n",
    "for i, m in enumerate(name_order):\n",
    "    colors_index[m]=f'C{i}'\n",
    "    for c in df.columns:\n",
    "        if 'CI'in c:\n",
    "            c_obj.add(c)\n",
    "for c in c_obj:\n",
    "    diff_vec = []\n",
    "    for j in tqdm(name_order):\n",
    "        # a = df[(df['model'] == j)][c].values\n",
    "        diff_vec.append(df[(df['model'] == j)][c].values)\n",
    "    diff_vec = np.array(diff_vec)\n",
    "    temp_diff_vec = diff_vec.copy()\n",
    "    a = np.argsort(np.linalg.norm(diff_vec, axis=0))\n",
    "    fig, ax = plt.subplots()\n",
    "    mat = diff_vec[:, a]\n",
    "    im = ax.matshow(mat)\n",
    "    ax.set_aspect(3000)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_xlabel(f'Sorted Trial index (n = {diff_vec.shape[1]:,})')\n",
    "    ax.set_yticks(range(len(name_order)), name_order)\n",
    "    ax.set_title(f'Norm Sorted SE Complexity Index {c.lower().replace(\"_\",\" \").capitalize()}')\n",
    "    fig.colorbar(im, location=\"bottom\")\n",
    "    plt.tight_layout()\n",
    "    save_large_plot(fig, f'norm_wise_orderd_matrix{c}_{len(d)}.png', d.data_tags)\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> spike count per simulation <h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#spike_count\n",
    "fig, ax = plt.subplots()\n",
    "datas = []\n",
    "for i in name_order:\n",
    "    datas.append(np.array(df[df['model'] == i]['spikes'].tolist()).sum(axis=1))\n",
    "    # a=np.mean(np.array(datas[-1]),axis=1)\n",
    "    # print(i, np.mean(np.array(datas[-1]),axis=1))\n",
    "names_for_plots_labels = [(mn + f\" ($\\mu$ = {np.round(np.mean(np.array(datas[i])), 2)})\") for i, mn in\n",
    "                          enumerate(models.values())]\n",
    "bins = np.arange(30) - 0.5\n",
    "\n",
    "\n",
    "ax.hist(datas, bins=bins,rwidth=0.75, label=names_for_plots_labels, alpha=1, align='mid')\n",
    "ax.set_title('Spike Count Per Trial')\n",
    "# ax.set_yscale('log')\n",
    "ax.set_xlabel('Number of Spikes in trail')\n",
    "ax.set_ylabel('Number of Occurrences')\n",
    "ax.set_xticks(bins[1:(8 * (bins.shape[0] // 8)):2] - 0.5, np.arange(0, (8 * (bins.shape[0] // 8)), 2))\n",
    "fig.legend(bbox_to_anchor=[0.9, 0.875])\n",
    "# save_large_plot(fig, 'spike_count.png', name_order)\n",
    "save_large_plot(fig,f'spike_count_{len(d)}.png',tags=d.data_tags)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in tqdm(df.columns):\n",
    "    if not ('ENTROPY' in i and 'CI' in i):\n",
    "        continue\n",
    "    print(i)\n",
    "    datas=[]\n",
    "    df = df.sort_values(by=['key'])\n",
    "    prev_index=None\n",
    "    indexes=None\n",
    "    for m in name_order:\n",
    "        prev_index=indexes\n",
    "        indexes=df[df['model'] == m]['key'].tolist()\n",
    "        datas.append(np.hstack(df[df['model'] == m][i].tolist()))\n",
    "        if prev_index is not None:\n",
    "            assert all(i==j for i,j in zip(prev_index,indexes)),'\\n'.join([('' if i==j else str((i,j)))for i,j in zip(prev_index,indexes)])\n",
    "        # datas.append(np.vstack(df[df['model'] == m][i].tolist()).sum(axis=1))\n",
    "    for j in combination_sorting(name_order):\n",
    "        first_index, second_index = j[0],j[1]\n",
    "        fig, ax = plt.subplots()\n",
    "        lims = (np.min(np.vstack((datas[first_index], datas[second_index]))),\n",
    "                np.max(np.vstack((datas[first_index], datas[second_index]))))\n",
    "        H, xedges, yedges = np.histogram2d(datas[first_index], datas[second_index], range=np.array([lims, lims]),\n",
    "                                           bins=200)\n",
    "        # replace zeroes with nan\n",
    "        H[H == 0] = np.nan\n",
    "        im = ax.imshow(H.T, interpolation='nearest', origin='lower', extent=[xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "                       )\n",
    "        # , norm=colors.LogNorm())\n",
    "        ax.plot(lims, lims, color='black')\n",
    "        slope, intercept, r_value, p_value, std_err = linregress(np.array(datas[first_index]), datas[second_index])\n",
    "        print(slope)\n",
    "        reg_intercep = intercept\n",
    "        reg_coef = slope\n",
    "        x = lims\n",
    "        y = [reg_intercep + lims[0] * reg_coef, reg_intercep + lims[1] * reg_coef]\n",
    "        ax.plot(x, y, color='red')\n",
    "        fig.colorbar(im)\n",
    "        ax.set_xlabel(models[name_order[first_index]])\n",
    "        ax.set_ylabel(models[name_order[second_index]])\n",
    "        ax.set_ylim(lims)\n",
    "        ax.set_xlim(lims)\n",
    "        ax.set_title(\n",
    "            f\"{models[name_order[first_index]]} and {models[name_order[second_index]]} trials {i} \\nn = {len(datas[second_index]) * 2:,} ,$R^2$ = {np.round(r_value ** 2, 4)}\")\n",
    "        fig\n",
    "        save_large_plot(fig, f\"pairwise_2dhist_{i}_{models[name_order[first_index]]}_{models[name_order[second_index]]}_{len(d)}.png\", tags=d.data_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%% print temporal mean and error\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# %% print temporal mean and error\n",
    "relevant_cols_msx=[]\n",
    "relevant_cols_ci=[]\n",
    "for i in df.columns:\n",
    "    if 'MSx'in i:\n",
    "        relevant_cols_msx.append(i)\n",
    "    elif 'CI' in i:\n",
    "        relevant_cols_ci.append(i)\n",
    "df = df.sort_values(['key'])\n",
    "datas = {}\n",
    "ci_data={}\n",
    "threshold=None\n",
    "# from scipy.stats import sem\n",
    "\n",
    "for m in tqdm(name_order):\n",
    "    datas[m]=[]\n",
    "    ci_data[m]=[]\n",
    "    for c in relevant_cols_msx:\n",
    "        datas[m].append(np.vstack(df[df['model'] == m][c].tolist()))\n",
    "    for c in relevant_cols_ci:\n",
    "        ci_data[m].append(np.vstack(df[df['model'] == m][c].tolist()))\n",
    "\n",
    "# ci_data = np.hstack(ci_data)\n",
    "# indexes=np.arange(ci_data[0].shape[0])\n",
    "for i,c in enumerate(relevant_cols_msx):\n",
    "    fig, ax = plt.subplots()\n",
    "    for m in tqdm(name_order):\n",
    "        print(c)\n",
    "        if threshold is not None:\n",
    "            mean = np.mean(datas[m][i], axis=0)\n",
    "            std =  np.std(datas[m][i], axis=0)\n",
    "        else:\n",
    "            mean = np.mean(datas[m][i], axis=0)\n",
    "            std = np.std(datas[m][i], axis=0)\n",
    "        ax.plot(np.arange(datas[m][i].shape[1]), mean, label=f'{models[m]}')\n",
    "        ax.fill_between(np.arange(datas[m][i].shape[1]), mean - std, mean + std, alpha=0.3)\n",
    "    ax.legend(loc='upper left')\n",
    "    # if threshold is not None:\n",
    "    # ax.set_title(\n",
    "    # f'Average SE Across Different Time Scales (n = {len(datas[0]) * len(datas):,}) \\nCi value {\"greater\" if direction > 0 else \"lower\"} than {threshold_value:0.4}')\n",
    "    # else:\n",
    "    #     ax.set_title(f'Average SE Across Different Time Scales (n = {len(datas[0]) * len(datas):,})')\n",
    "    ax.set_xlabel('Time Scales')\n",
    "    ax.set_ylabel('SE value')\n",
    "    ax.set_title(c.lower().replace('_',' ').capitalize())\n",
    "    save_large_plot(fig,f'temporal_msx_{c}_{len(d)}.png',tags=d.data_tags)\n",
    "\n",
    "    fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
